@book{russel2010,
	added-at = {2020-02-01T18:23:11.000+0100},
	author = {Russell, Stuart and Norvig, Peter},
	biburl = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
	edition = 3,
	interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
	intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
	keywords = {ties4530},
	publisher = {Prentice Hall},
	timestamp = {2020-02-01T18:23:11.000+0100},
	title = {Artificial Intelligence: A Modern Approach},
	year = 2010
}

@article{lasi2014industry,
	author = "Lasi, Heiner; Fettke and Peter; Feld and Thomas; and Hoffmann, Michael",
	title = ""Industry 4",
	journal = "0, " Business & Information Systems Engineering:",
	volume = "6:",
	number = "4",
	pages = "239--242",
	year = 2014
}

@book{gonzalez2008digital,
	abstract = {Completely self-contained-and heavily illustrated-this introduction to basic concepts and methodologies for digital image processing is written at a level that truly is suitable for seniors and first-year graduate students in almost any technical discipline. The leading textbook in its field for more than twenty years, it continues its cutting-edge focus on contemporary developments in all mainstream areas of image processing-e.g., image fundamentals, image enhancement in the spatial and frequency domains, restoration, color image processing, wavelets, image compression, morphology, segmentation, image description, and the fundamentals of object recognition. It focuses on material that is fundamental and has a broad scope of application.},
	added-at = {2014-07-10T10:50:48.000+0200},
	address = {Upper Saddle River, N.J.},
	author = {Gonzalez, Rafael C. and Woods, Richard E.},
	biburl = {https://www.bibsonomy.org/bibtex/2bd73f6e1350f31aa5da16268e2b1e694/alex_ruff},
	description = {Digital Image Processing (3rd Edition): Rafael C. Gonzalez, Richard E. Woods: 9780131687288: Amazon.com: Books},
	isbn = {9780131687288 013168728X 9780135052679 013505267X},
	keywords = {book image_processing},
	publisher = {Prentice Hall},
	refid = {137312858},
	timestamp = {2014-07-10T10:50:48.000+0200},
	title = {Digital image processing},
	url = {http://www.amazon.com/Digital-Image-Processing-3rd-Edition/dp/013168728X},
	year = 2008
}


@book{cv_algandapp,
	author = {Szeliski, Richard},
	title = {Computer Vision: Algorithms and Applications},
	year = {2010},
	isbn = {1848829345},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	edition = {1st},
	abstract = {Humans perceive the three-dimensional structure of the world with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem and what is the current state of the art? Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging, and for fun, consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos. More than just a source of recipes, this exceptionally authoritative and comprehensive textbook/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting them to produce descriptions of a scene. These problems are also analyzed using statistical models and solved using rigorous engineering techniques Topics and features: structured to support active curricula and project-oriented courses, with tips in the Introduction for using the book in a variety of customized courses; presents exercises at the end of each chapter with a heavy emphasis on testing algorithms and containing numerous suggestions for small mid-term projects; provides additional material and more detailed mathematical topics in the Appendices, which cover linear algebra, numerical techniques, and Bayesian estimation theory; suggests additional reading at the end of each chapter, including the latest research in each sub-field, in addition to a full Bibliography at the end of the book; supplies supplementary course material for students at the associated website, http://szeliski.org/Book/. Suitable for an upper-level undergraduate or graduate-level course in computer science or engineering, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries. Its design and exposition also make it eminently suitable as a unique reference to the fundamental techniques and current research literature in computer vision.}
}

@article{HARALICK1985100,
	title = {Image segmentation techniques},
	journal = {Computer Vision, Graphics, and Image Processing},
	volume = {29},
	number = {1},
	pages = {100-132},
	year = {1985},
	issn = {0734-189X},
	doi = {https://doi.org/10.1016/S0734-189X(85)90153-7},
	url = {https://www.sciencedirect.com/science/article/pii/S0734189X85901537},
	author = {Robert M. Haralick and Linda G. Shapiro},
	abstract = {There are now a wide variety of image segmentation techniques, some considered general purpose and some designed for specific classes of images. These techniques can be classified as: measurement space guided spatial clustering, single linkage region growing schemes, hybrid linkage region growing schemes, centroid linkage region growing schemes, spatial clustering schemes, and split-and-merge schemes. In this paper, each of the major classes of image segmentation techniques is defined and several specific examples of each class of algorithm are described. The techniques are illustrated with examples of segmentations performed on real images.}
}


@article{Litjens_2017,
	doi = {10.1016/j.media.2017.07.005},
	url = {https://doi.org/10.1016%2Fj.media.2017.07.005},
	year = 2017,
	month = {dec},
	publisher = {Elsevier {BV}
	},
	volume = {42},
	pages = {60--88},
	author = {Geert Litjens and Thijs Kooi and Babak Ehteshami Bejnordi and Arnaud Arindra Adiyoso Setio and Francesco Ciompi and Mohsen Ghafoorian and Jeroen A.W.M. van der Laak and Bram van Ginneken and Clara I. S{\'{a}}nchez},
	title = {A survey on deep learning in medical image analysis},
	journal = {Medical Image Analysis}
}

@article{shen2017,
	author = {Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
	title = {Deep Learning in Medical Image Analysis},
	journal = {Annual Review of Biomedical Engineering},
	volume = {19},
	number = {1},
	pages = {221-248},
	year = {2017},
	doi = {10.1146/annurev-bioeng-071516-044442},
	note ={PMID: 28301734},
	
	URL = { 
	https://doi.org/10.1146/annurev-bioeng-071516-044442
	},
	eprint = {  https://doi.org/10.1146/annurev-bioeng-071516-044442
	}
	,
	abstract = { This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement. }
}

@misc{chen2017deeplab,
	title={DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs}, 
	author={Liang-Chieh Chen and George Papandreou and Iasonas Kokkinos and Kevin Murphy and Alan L. Yuille},
	year={2017},
	eprint={1606.00915},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{garciagarcia2017review,
	title={A Review on Deep Learning Techniques Applied to Semantic Segmentation}, 
	author={Alberto Garcia-Garcia and Sergio Orts-Escolano and Sergiu Oprea and Victor Villena-Martinez and Jose Garcia-Rodriguez},
	year={2017},
	eprint={1704.06857},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@article{tripSteels,
	author = {Bhadeshia, H},
	year = {2002},
	month = {01},
	pages = {},
	title = {TRIP-assisted steels?},
	volume = {42},
	journal = {ISIJ International},
	doi = {10.2355/isijinternational.42.1059}
}

@article{ALLAIN2004158,
	title = {Correlations between the calculated stacking fault energy and the plasticity mechanisms in Fe–Mn–C alloys},
	journal = {Materials Science and Engineering: A},
	volume = {387-389},
	pages = {158-162},
	year = {2004},
	note = {13th International Conference on the Strength of Materials},
	issn = {0921-5093},
	doi = {https://doi.org/10.1016/j.msea.2004.01.059},
	url = {https://www.sciencedirect.com/science/article/pii/S0921509304004356},
	author = {S. Allain and J.-P. Chateau and O. Bouaziz and S. Migot and N. Guelton},
	keywords = {Stacking fault energy, Gibbs energy, Néel temperature, Mechanical twinning, Martensitic transformation},
	abstract = {A model is proposed for the evaluation of the stacking fault energy (SFE) in Fe–Mn–C austenitic alloys, at different temperatures. It accounts for the variation of the Gibbs energy of each element during the austenite to ε martensite transformation, plus their interactions. The Gibbs energy due to the antiferromagnetic to paramagnetic transition is also taken into account. The required data have been obtained from the literature. The result shows a decrease of the SFE with temperature, with a saturation below the austenite Néel temperature. The result agrees with the mechanical and thermal martensitic transformation limits proposed by Schumann. The plasticity mechanisms depend on the SFE. The mechanical martensitic transformation occurs below 18mJ/m2, and twinning between 12 and 35mJ/m2, in agreement with the tensile tests and the deformation microstructures observed in an Fe–22wt.% Mn–0.6wt.% C alloy at 77, 293 and 693K.}
}

@article{BOUAZIZ2011141,
	title = {High manganese austenitic twinning induced plasticity steels: A review of the microstructure properties relationships},
	journal = {Current Opinion in Solid State and Materials Science},
	volume = {15},
	number = {4},
	pages = {141-168},
	year = {2011},
	issn = {1359-0286},
	doi = {https://doi.org/10.1016/j.cossms.2011.04.002},
	url = {https://www.sciencedirect.com/science/article/pii/S1359028611000179},
	author = {O. Bouaziz and S. Allain and C.P. Scott and P. Cugy and D. Barbier},
	keywords = {Steel, Austenite, Twin, Microstructure, Properties, High manganese, TWIP},
	abstract = {A significant increase in the research activity dedicated to high manganese TWIP steels has occurred during the past five years, motivated by the breakthrough combination of strength and ductility possessed by these alloys. Here a review of the relations between microstructure and mechanical properties is presented focusing on plasticity mechanisms, strain-hardening, yield stress, texture, fracture and fatigue. This summarized knowledge explains why TWIP steel metallurgy is currently a topic of great practical interest and fundamental importance. Finally, this publication indicates some of the main avenues for future investigations required in order to sustain the quality and the dynamism in this field.}
}

@inproceedings{NIPS2012_imagenet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012}
}

@Article{LeCun2015,
	author={LeCun, Yann
	and Bengio, Yoshua
	and Hinton, Geoffrey},
	title={Deep learning},
	journal={Nature},
	year={2015},
	month={May},
	day={01},
	volume={521},
	number={7553},
	pages={436-444},
	abstract={Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	issn={1476-4687},
	doi={10.1038/nature14539},
	url={https://doi.org/10.1038/nature14539}
}

@Book{GoodBengCour16,
	Title                    = {Deep Learning},
	Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
	Publisher                = {MIT Press},
	Year                     = {2016},
	Address                  = {Cambridge, MA, USA},
	url                     = {http://www.deeplearningbook.org}
}

@misc{cao2021swinunet,
	title={Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation}, 
	author={Hu Cao and Yueyue Wang and Joy Chen and Dongsheng Jiang and Xiaopeng Zhang and Qi Tian and Manning Wang},
	year={2021},
	eprint={2105.05537},
	archivePrefix={arXiv},
	primaryClass={eess.IV}
}


@Article{sym13071176,
	AUTHOR = {Boikov, Aleksei and Payor, Vladimir and Savelev, Roman and Kolesnikov, Alexandr},
	TITLE = {Synthetic Data Generation for Steel Defect Detection and Classification Using Deep Learning},
	JOURNAL = {Symmetry},
	VOLUME = {13},
	YEAR = {2021},
	NUMBER = {7},
	ARTICLE-NUMBER = {1176},
	URL = {https://www.mdpi.com/2073-8994/13/7/1176},
	ISSN = {2073-8994},
	ABSTRACT = {The paper presents a methodology for training neural networks for vision tasks on synthesized data on the example of steel defect recognition in automated production control systems. The article describes the process of dataset procedural generation of steel slab defects with a symmetrical distribution. The results of training two neural networks Unet and Xception on a generated data grid and testing them on real data are presented. The performance of these neural networks was assessed using real data from the Severstal: Steel Defect Detection set. In both cases, the neural networks showed good results in the classification and segmentation of surface defects of steel workpieces in the image. Dice score on synthetic data reaches 0.62, and accuracy—0.81.},
	DOI = {10.3390/sym13071176}
}

@article{LAI2009665,
	title = {Rapid and effective segmentation of 3D models using random walks},
	journal = {Computer Aided Geometric Design},
	volume = {26},
	number = {6},
	pages = {665-679},
	year = {2009},
	note = {Solid and Physical Modeling 2008},
	issn = {0167-8396},
	doi = {https://doi.org/10.1016/j.cagd.2008.09.007},
	url = {https://www.sciencedirect.com/science/article/pii/S0167839608000940},
	author = {Yu-Kun Lai and Shi-Min Hu and Ralph R. Martin and Paul L. Rosin},
	keywords = {Model segmentation, Random walks, Interactive},
	abstract = {3D models are now widely available for use in various applications. The demand for automatic model analysis and understanding is ever increasing. Model segmentation is an important step towards model understanding, and acts as a useful tool for different model processing applications, e.g. reverse engineering and modeling by example. We extend a random walk method used previously for image segmentation to give algorithms for both interactive and automatic model segmentation. This method is extremely efficient, and scales almost linearly with the number of faces, and the number of regions. For models of moderate size, interactive performance is achieved with commodity PCs. We demonstrate that this method can be applied to both triangle meshes and point cloud data. It is easy-to-implement, robust to noise in the model, and yields results suitable for downstream applications for both graphical and engineering models.}
}

@Article{Durmaz2021,
	author={Durmaz, Ali Riza
	and M{\"u}ller, Martin
	and Lei, Bo
	and Thomas, Akhil
	and Britz, Dominik
	and Holm, Elizabeth A.
	and Eberl, Chris
	and M{\"u}cklich, Frank
	and Gumbsch, Peter},
	title={A deep learning approach for complex microstructure inference},
	journal={Nature Communications},
	year={2021},
	month={Nov},
	day={01},
	volume={12},
	number={1},
	pages={6272},
	abstract={Automated, reliable, and objective microstructure inference from micrographs is essential for a comprehensive understanding of process-microstructure-property relations and tailored materials development. However, such inference, with the increasing complexity of microstructures, requires advanced segmentation methodologies. While deep learning offers new opportunities, an intuition about the required data quality/quantity and a methodological guideline for microstructure quantification is still missing. This, along with deep learning's seemingly intransparent decision-making process, hampers its breakthrough in this field. We apply a multidisciplinary deep learning approach, devoting equal attention to specimen preparation and imaging, and train distinct U-Net architectures with 30--50 micrographs of different imaging modalities and electron backscatter diffraction-informed annotations. On the challenging task of lath-bainite segmentation in complex-phase steel, we achieve accuracies of 90{\%} rivaling expert segmentations. Further, we discuss the impact of image context, pre-training with domain-extrinsic data, and data augmentation. Network visualization techniques demonstrate plausible model decisions based on grain boundary morphology.},
	issn={2041-1723},
	doi={10.1038/s41467-021-26565-5},
	url={https://doi.org/10.1038/s41467-021-26565-5}
}

@article{LUENGO2022232,
	title = {A tutorial on the segmentation of metallographic images: Taxonomy, new MetalDAM dataset, deep learning-based ensemble model, experimental analysis and challenges},
	journal = {Information Fusion},
	volume = {78},
	pages = {232-253},
	year = {2022},
	issn = {1566-2535},
	doi = {https://doi.org/10.1016/j.inffus.2021.09.018},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253521001949},
	author = {Julián Luengo and Raúl Moreno and Iván Sevillano and David Charte and Adrián Peláez-Vegas and Marta Fernández-Moreno and Pablo Mesejo and Francisco Herrera},
	keywords = {Image segmentation, Metallography, Machine learning, Deep learning, Microscopy images, Computer vision},
	abstract = {Image segmentation is an important issue in many industrial processes, with high potential to enhance the manufacturing process derived from raw material imaging. For example, metal phases contained in microstructures yield information on the physical properties of the steel. Existing prior literature has been devoted to develop specific computer vision techniques able to tackle a single problem involving a particular type of metallographic image. However, the field lacks a comprehensive tutorial on the different types of techniques, methodologies, their generalizations and the algorithms that can be applied in each scenario. This paper aims to fill this gap. First, the typologies of computer vision techniques to perform the segmentation of metallographic images are reviewed and categorized in a taxonomy. Second, the potential utilization of pixel similarity is discussed by introducing novel deep learning-based ensemble techniques that exploit this information. Third, a thorough comparison of the reviewed techniques is carried out in two openly available real-world datasets, one of them being a newly published dataset directly provided by ArcelorMittal, which opens up the discussion on the strengths and weaknesses of each technique and the appropriate application framework for each one. Finally, the open challenges in the topic are discussed, aiming to provide guidance in future research to cover the existing gaps.}
}

@Article{Roberts2019,
	author={Roberts, Graham
	and Haile, Simon Y.
	and Sainju, Rajat
	and Edwards, Danny J.
	and Hutchinson, Brian
	and Zhu, Yuanyuan},
	title={Deep Learning for Semantic Segmentation of Defects in Advanced STEM Images of Steels},
	journal={Scientific Reports},
	year={2019},
	month={Sep},
	day={04},
	volume={9},
	number={1},
	pages={12744},
	abstract={Crystalline materials exhibit long-range ordered lattice unit, within which resides nonperiodic structural features called defects. These crystallographic defects play a vital role in determining the physical and mechanical properties of a wide range of material systems. While computer vision has demonstrated success in recognizing feature patterns in images with well-defined contrast, automated identification of nanometer scale crystallographic defects in electron micrographs governed by complex contrast mechanisms is still a challenging task. Here, building upon an advanced defect imaging mode that offers high feature clarity, we introduce DefectSegNet - a new convolutional neural network (CNN) architecture that performs semantic segmentation of three common crystallographic defects in structural alloys: dislocation lines, precipitates and voids. Results from supervised training on a small set of high-quality defect images of steels show high pixel-wise accuracy across all three types of defects: 91.60{\thinspace}{\textpm}{\thinspace}1.77{\%} on dislocations, 93.39{\thinspace}{\textpm}{\thinspace}1.00{\%} on precipitates, and 98.85{\thinspace}{\textpm}{\thinspace}0.56{\%} on voids. We discuss the sources of uncertainties in CNN prediction and the training data in terms of feature density, representation and homogeneity and their effects on deep learning performance. Further defect quantification using DefectSegNet prediction outperforms human expert average, presenting a promising new workflow for fast and statistically meaningful quantification of materials defects.},
	issn={2045-2322},
	doi={10.1038/s41598-019-49105-0},
	url={https://doi.org/10.1038/s41598-019-49105-0}
}

@misc{ronneberger2015unet,
	title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
	author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
	year={2015},
	eprint={1505.04597},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}
